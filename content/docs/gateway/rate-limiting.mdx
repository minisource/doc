---
title: Rate Limiting
description: Configure rate limiting in the API Gateway
---

import { Tab, Tabs } from 'fumadocs-ui/components/tabs';
import { Callout } from 'fumadocs-ui/components/callout';

# Rate Limiting

The API Gateway implements a token bucket rate limiter with Redis backend and in-memory fallback.

## How It Works

```
Request → Check Bucket → Allow/Deny → Update Bucket
             ↓                            ↓
         Redis/Memory              Decrement Token
```

The token bucket algorithm:
1. Each client has a bucket of tokens
2. Tokens refill at `requestsPerSec` rate
3. Each request consumes one token
4. When bucket is empty, requests are rejected

## Configuration

### Global Rate Limits

```bash
# Environment variables
RATE_LIMIT_ENABLED=true
RATE_LIMIT_RPS=100        # Requests per second
RATE_LIMIT_BURST=200      # Maximum burst size
RATE_LIMIT_CLEANUP=1m     # Cleanup interval for expired entries
```

### Per-Route Rate Limits

Configure in `config/routes.yaml`:

```yaml
routes:
  - path: /api/v1/auth/login
    service: auth
    methods: [POST]
    public: true
    rateLimit:
      requestsPerSec: 10   # Stricter limit for login
      burstSize: 20

  - path: /api/v1/auth/register
    service: auth
    methods: [POST]
    public: true
    rateLimit:
      requestsPerSec: 5    # Even stricter for registration
      burstSize: 10

  - path: /api/v1/notifications/send
    service: notifier
    methods: [POST]
    rateLimit:
      requestsPerSec: 50   # Higher limit for notifications
      burstSize: 100
```

## Rate Limit Headers

The gateway adds rate limit headers to responses:

| Header | Description |
|--------|-------------|
| `X-RateLimit-Limit` | Maximum requests per second |
| `X-RateLimit-Remaining` | Remaining requests in current window |
| `X-RateLimit-Reset` | Unix timestamp when limit resets |

Example response:

```http
HTTP/1.1 200 OK
X-RateLimit-Limit: 100
X-RateLimit-Remaining: 95
X-RateLimit-Reset: 1704067200
```

## Rate Limit Exceeded

When limit is exceeded, the gateway returns `429 Too Many Requests`:

```json
{
  "error": "rate_limit_exceeded",
  "message": "Too many requests, please try again later",
  "retry_after": 5
}
```

## Key Generation

Rate limit keys are generated based on:

1. **Authenticated Users**: `ratelimit:{user_id}:{path}`
2. **Anonymous Users**: `ratelimit:ip:{ip_address}:{path}`

```go
func (rl *RateLimiter) createKey(c *fiber.Ctx) string {
    if userID := c.Locals("user_id"); userID != nil {
        return fmt.Sprintf("ratelimit:%s:%s", userID, c.Path())
    }
    return fmt.Sprintf("ratelimit:ip:%s:%s", c.IP(), c.Path())
}
```

## Redis Backend

When Redis is available, rate limiting uses distributed counters:

```bash
# Redis configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0
```

Benefits of Redis:
- Shared state across gateway replicas
- Persistence across restarts
- Atomic operations

## In-Memory Fallback

If Redis is unavailable, the gateway falls back to in-memory rate limiting:

<Callout type="warning">
In-memory rate limiting is per-instance. In a multi-replica deployment without Redis, each gateway instance has separate limits.
</Callout>

```go
// LocalLimiter is an in-memory rate limiter fallback
type LocalLimiter struct {
    mu       sync.RWMutex
    requests map[string]*rateBucket
    cfg      config.RateLimitConfig
}
```

## Monitoring

Rate limit metrics are exposed via Prometheus:

```
# Rate limit exceeded counter
gateway_rate_limit_exceeded_total{path="/api/v1/auth/login"} 42
```

Query in Grafana:

```promql
# Rate limit exceeded per minute
rate(gateway_rate_limit_exceeded_total[1m])

# Top paths hitting rate limits
topk(10, sum by (path) (gateway_rate_limit_exceeded_total))
```

## Best Practices

### Sensitive Endpoints

Apply stricter limits to sensitive endpoints:

```yaml
# Login - prevent brute force
- path: /api/v1/auth/login
  rateLimit:
    requestsPerSec: 5
    burstSize: 10

# Password reset - prevent abuse
- path: /api/v1/auth/forgot-password
  rateLimit:
    requestsPerSec: 3
    burstSize: 5
```

### API Endpoints

Set reasonable limits based on expected usage:

```yaml
# Standard API - moderate limits
- path: /api/v1/users
  rateLimit:
    requestsPerSec: 50
    burstSize: 100

# Heavy endpoints - lower limits
- path: /api/v1/reports/generate
  rateLimit:
    requestsPerSec: 5
    burstSize: 10
```

### Disable for Internal Services

For service-to-service calls, consider higher limits or exemptions:

```go
// Skip rate limiting for internal IPs
if isInternalIP(c.IP()) {
    return c.Next()
}
```
